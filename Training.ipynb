{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7943639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras import layers,models,metrics,optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8dce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: savedModels/14Inputs\\assets\n"
     ]
    }
   ],
   "source": [
    "CNNmodel = models.Sequential()\n",
    "CNNmodel.add(layers.Conv2D(128,(5,5),strides = 1, activation =\"relu\",padding = \"valid\" ,input_shape=(17,17,14)))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "CNNmodel.add(layers.Conv2D(1,(1,1),strides = 1))\n",
    "CNNmodel.add(layers.Flatten())\n",
    "CNNmodel.load_weights(\"trainingMhex3rditer8layers26inputs/cp-0010.ckpt\")\n",
    "CNNmodel.save(\"savedModels/14Inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63d774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'positions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavedModels/2Inputs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39munravel_index(np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39mreshape(new_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mpositions\u001b[49m[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m6\u001b[39m]),(\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m13\u001b[39m)),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m),(\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m13\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'positions' is not defined"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('savedModels/2Inputs')\n",
    "np.unravel_index(np.argmax(np.reshape(new_model.predict(positions[5:6]),(13,13)),axis=None),(13,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3baeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/scoredPositionsFull.npz')\n",
    "actionData = np.load('data/actions.npz')\n",
    "positions = data['positions']\n",
    "positions = positions.transpose(0,2,3,1)\n",
    "\n",
    "actions = actionData['actions']\n",
    "actions = np.delete(actions,0,1)\n",
    "actions = np.delete(actions,0,1)\n",
    "\n",
    "actions = np.delete(actions,14,1)\n",
    "actions = np.delete(actions,13,1)\n",
    "actions = np.delete(actions,0,2)\n",
    "actions = np.delete(actions,0,2)\n",
    "\n",
    "actions = np.delete(actions,14,2)\n",
    "actions = np.delete(actions,13,2)\n",
    "actions = np.reshape(actions,(539998,169))\n",
    "actions = np.where(actions == 1)\n",
    "actions = actions[1]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5492ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bdcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam()\n",
    "CNNmodel.compile(optimizer = opt, loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics = [metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"trainingSGD/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,verbose = 1, save_weights_only = True, save_freq = 3985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0cc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e52cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_test = positions[-30000:]\n",
    "actions_test = actions[-30000:]\n",
    "positions_train = positions[:-30000]\n",
    "actions_train = actions[:-30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2643c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positions[:20][0])\n",
    "print(positions[:20][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a7ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained = CNNmodel.fit(positions_train,actions_train,batch_size = 128, epochs = 50,validation_data= (positions_test,actions_test),callbacks= [cp_callback,callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687d9896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.7788455486297607,\n",
       "  2.8180606365203857,\n",
       "  2.7739062309265137,\n",
       "  2.74249267578125,\n",
       "  2.7072224617004395,\n",
       "  2.7111639976501465,\n",
       "  2.6776983737945557,\n",
       "  2.6646854877471924,\n",
       "  2.6612935066223145,\n",
       "  2.642488956451416,\n",
       "  2.595977544784546,\n",
       "  2.6104578971862793,\n",
       "  2.6225745677948,\n",
       "  2.5721933841705322,\n",
       "  2.595229148864746,\n",
       "  2.536811590194702,\n",
       "  2.5223264694213867,\n",
       "  2.505760431289673,\n",
       "  2.5640907287597656,\n",
       "  2.490449905395508,\n",
       "  2.5371432304382324,\n",
       "  2.4701790809631348,\n",
       "  2.4989943504333496,\n",
       "  2.435443639755249,\n",
       "  2.4067840576171875,\n",
       "  2.4105587005615234,\n",
       "  2.3761987686157227,\n",
       "  2.4080262184143066,\n",
       "  2.4449756145477295,\n",
       "  2.4158260822296143,\n",
       "  2.4274518489837646,\n",
       "  2.4598395824432373],\n",
       " 'sparse_categorical_accuracy': [0.2682676911354065,\n",
       "  0.2665562629699707,\n",
       "  0.2716096043586731,\n",
       "  0.2749677002429962,\n",
       "  0.27827343344688416,\n",
       "  0.2773105800151825,\n",
       "  0.28132107853889465,\n",
       "  0.2841953635215759,\n",
       "  0.2848201394081116,\n",
       "  0.2884049117565155,\n",
       "  0.2923239767551422,\n",
       "  0.29238492250442505,\n",
       "  0.29131823778152466,\n",
       "  0.298471599817276,\n",
       "  0.29738399386405945,\n",
       "  0.3031154274940491,\n",
       "  0.3056049644947052,\n",
       "  0.3075592815876007,\n",
       "  0.29923829436302185,\n",
       "  0.30867069959640503,\n",
       "  0.3036220967769623,\n",
       "  0.31370022892951965,\n",
       "  0.3059106767177582,\n",
       "  0.32181742787361145,\n",
       "  0.3249812424182892,\n",
       "  0.32550981640815735,\n",
       "  0.3305688798427582,\n",
       "  0.3261469602584839,\n",
       "  0.32107454538345337,\n",
       "  0.3279736340045929,\n",
       "  0.32571646571159363,\n",
       "  0.3231878876686096],\n",
       " 'val_loss': [3.1336753368377686,\n",
       "  2.7942392826080322,\n",
       "  2.8663504123687744,\n",
       "  2.741158962249756,\n",
       "  2.6615443229675293,\n",
       "  2.7498226165771484,\n",
       "  2.7047836780548096,\n",
       "  2.697568655014038,\n",
       "  2.6504411697387695,\n",
       "  2.6331379413604736,\n",
       "  2.7174365520477295,\n",
       "  2.658356189727783,\n",
       "  2.6274802684783936,\n",
       "  2.5857338905334473,\n",
       "  2.6276674270629883,\n",
       "  2.6980457305908203,\n",
       "  2.540959358215332,\n",
       "  2.679637908935547,\n",
       "  2.569896697998047,\n",
       "  2.46642804145813,\n",
       "  2.4678614139556885,\n",
       "  2.4716744422912598,\n",
       "  2.438293695449829,\n",
       "  2.4281604290008545,\n",
       "  2.3966729640960693,\n",
       "  2.403766632080078,\n",
       "  2.3724873065948486,\n",
       "  2.484963893890381,\n",
       "  2.4576797485351562,\n",
       "  2.404031991958618,\n",
       "  2.430952310562134,\n",
       "  2.4653706550598145],\n",
       " 'val_sparse_categorical_accuracy': [0.24513334035873413,\n",
       "  0.2641666531562805,\n",
       "  0.26213333010673523,\n",
       "  0.2736666798591614,\n",
       "  0.27709999680519104,\n",
       "  0.2628999948501587,\n",
       "  0.2739666700363159,\n",
       "  0.2734000086784363,\n",
       "  0.27489998936653137,\n",
       "  0.28893333673477173,\n",
       "  0.2698666751384735,\n",
       "  0.26739999651908875,\n",
       "  0.28433331847190857,\n",
       "  0.2911333441734314,\n",
       "  0.28806665539741516,\n",
       "  0.2803666591644287,\n",
       "  0.3031333386898041,\n",
       "  0.26996666193008423,\n",
       "  0.28973332047462463,\n",
       "  0.313400000333786,\n",
       "  0.31220000982284546,\n",
       "  0.31049999594688416,\n",
       "  0.3174000084400177,\n",
       "  0.32163333892822266,\n",
       "  0.32260000705718994,\n",
       "  0.3275333344936371,\n",
       "  0.32556667923927307,\n",
       "  0.31976667046546936,\n",
       "  0.3178333342075348,\n",
       "  0.3275333344936371,\n",
       "  0.3236333429813385,\n",
       "  0.31236666440963745]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict[6].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97fea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = output_dict[2]\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892e9283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('2HiddenLayer128BatchDoubleData2Inputs.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b8abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41f2ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12412811887359791751\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6972309504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9364139211471760199\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145ef96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8288/8288 [==============================] - 413s 48ms/step - loss: 1.9536 - sparse_categorical_accuracy: 0.4999 - val_loss: 1.8520 - val_sparse_categorical_accuracy: 0.5143\n",
      "Epoch 2/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 1.9227 - sparse_categorical_accuracy: 0.5043 - val_loss: 1.8300 - val_sparse_categorical_accuracy: 0.5143\n",
      "Epoch 3/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 2.1974 - sparse_categorical_accuracy: 0.4664 - val_loss: 2.0259 - val_sparse_categorical_accuracy: 0.4872\n",
      "Epoch 4/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 1.8991 - sparse_categorical_accuracy: 0.5077 - val_loss: 1.8675 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 5/100\n",
      "7866/8288 [===========================>..] - ETA: 18s - loss: 1.9073 - sparse_categorical_accuracy: 0.5076\n",
      "Epoch 5: saving model to trainingMhex3rditer8layers26inputs\\cp-0005.ckpt\n",
      "8288/8288 [==============================] - 401s 48ms/step - loss: 1.9024 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.8072 - val_sparse_categorical_accuracy: 0.5186\n",
      "Epoch 6/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 1.8519 - sparse_categorical_accuracy: 0.5172 - val_loss: 1.7967 - val_sparse_categorical_accuracy: 0.5261\n",
      "Epoch 7/100\n",
      "8288/8288 [==============================] - 401s 48ms/step - loss: 1.8154 - sparse_categorical_accuracy: 0.5194 - val_loss: 1.8114 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 8/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 1.9805 - sparse_categorical_accuracy: 0.4963 - val_loss: 5.1299 - val_sparse_categorical_accuracy: 0.0045\n",
      "Epoch 9/100\n",
      "8288/8288 [==============================] - 401s 48ms/step - loss: 5.1300 - sparse_categorical_accuracy: 0.0044 - val_loss: 5.1299 - val_sparse_categorical_accuracy: 0.0043\n",
      "Epoch 10/100\n",
      "7447/8288 [=========================>....] - ETA: 36s - loss: 5.1302 - sparse_categorical_accuracy: 0.0044\n",
      "Epoch 10: saving model to trainingMhex3rditer8layers26inputs\\cp-0010.ckpt\n",
      "8288/8288 [==============================] - 401s 48ms/step - loss: 5.1300 - sparse_categorical_accuracy: 0.0044 - val_loss: 5.1299 - val_sparse_categorical_accuracy: 0.0043\n",
      "Epoch 11/100\n",
      "8288/8288 [==============================] - 400s 48ms/step - loss: 5.1300 - sparse_categorical_accuracy: 0.0053 - val_loss: 5.1299 - val_sparse_categorical_accuracy: 0.0058\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras import layers,models,metrics,optimizers,initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "data = np.load('data/mohexPositions.npz')\n",
    "actionData = np.load('data/mohexActions.npz')\n",
    "positions = data['positions']\n",
    "positions = positions.transpose(0,2,3,1)\n",
    "# positions = np.delete(positions,np.s_[2:18],3)\n",
    "\n",
    "\n",
    "actions = actionData['actions']\n",
    "actions = np.delete(actions,0,1)\n",
    "actions = np.delete(actions,0,1)\n",
    "\n",
    "actions = np.delete(actions,14,1)\n",
    "actions = np.delete(actions,13,1)\n",
    "actions = np.delete(actions,0,2)\n",
    "actions = np.delete(actions,0,2)\n",
    "\n",
    "actions = np.delete(actions,14,2)\n",
    "actions = np.delete(actions,13,2)\n",
    "\n",
    "actions = np.reshape(actions,(1760832,169))\n",
    "\n",
    "actions = np.where(actions == 1)\n",
    "\n",
    "actions = actions[1]\n",
    "\n",
    "\n",
    "\n",
    "# positions_train =np.concatenate((positions[:-30000], positions_mirror), axis= 0) \n",
    "# actions_train =np.concatenate((actions[:-30000], actions_mirror), axis= 0) \n",
    "inputs = [(1,1),(2,18),(6,18),(2,6)] \n",
    "for k in range (3,4):\n",
    "    if k > 0: \n",
    "        positions = np.delete(positions,np.s_[inputs[k][0]:inputs[k][1]],3)\n",
    "    positions_test = positions[-200000:] \n",
    "    actions_test = actions[-200000:]\n",
    "    actions_train = actions[500000:-200000]\n",
    "    positions_train = positions[500000:-200000]\n",
    "    for i in range(8,9):\n",
    "\n",
    "        model = models.Sequential()\n",
    "    #     init_stddev = math.sqrt(2.0 / (18 * 5 * 5))\n",
    "        if k > 0:\n",
    "            model.add(layers.Conv2D(128,(5,5),strides = 1, activation =\"relu\",padding = \"valid\" ,input_shape=(17,17,18 - (inputs[k][1] - inputs[k][0]))))\n",
    "        else:\n",
    "            model.add(layers.Conv2D(128,(5,5),strides = 1, activation =\"relu\",padding = \"valid\" ,input_shape=(17,17,18)))\n",
    "       \n",
    "        for j in range (0,i):\n",
    "    #         init_stddev = math.sqrt(2.0 / (128 * 3 * 3))\n",
    "            model.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "\n",
    "        model.add(layers.Conv2D(1,(1,1),strides = 1))\n",
    "        model.add(layers.Flatten())\n",
    "        model.load_weights(\"trainingMhex2nditer8layers26inputs/cp-0020.ckpt\")\n",
    "            \n",
    "        checkpoint_path = \"trainingMhex3rditer\" + str(i) + \"layers\" + str(inputs[k][0]) + str(inputs[k][1]) +  \"inputs/cp-{epoch:04d}.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,verbose = 1, save_weights_only = True, save_freq = 8204 * 5)\n",
    "        opt = optimizers.Adam(0.00001)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "        model.compile(optimizer = opt, loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics = [metrics.SparseCategoricalAccuracy()])\n",
    "        output = model.fit(positions_train,actions_train,batch_size = 128, epochs = 100,validation_data= (positions_test,actions_test),callbacks= [cp_callback,callback])\n",
    "        np.save(\"history/historyMhex3rditer\" + str(i) + \"layers\" + str(k), output.history)\n",
    "\n",
    "        \n",
    "            \n",
    "    \n",
    "#         checkpoint_path = \"training\" + str(i) + \"layers2nditer\" + str(inputs[k][0]) + str(inputs[k][1]) +  \"inputs/cp-{epoch:04d}.ckpt\"\n",
    "#         checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "#         cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,verbose = 1, save_weights_only = True, save_freq = 8204 * 5)\n",
    "#         opt = optimizers.Adam(0.0001)\n",
    "#         callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "\n",
    "#         model.compile(optimizer = opt, loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics = [metrics.SparseCategoricalAccuracy()])\n",
    "#         output = model.fit(positions_train,actions_train,batch_size = 128, epochs = 40,validation_data= (positions_test,actions_test),callbacks= [cp_callback,callback])\n",
    "#         np.save(\"history/history2nd\" + str(k), output.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9716ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199e2bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.670104742050171,\n",
       "  3.2186014652252197,\n",
       "  3.1971969604492188,\n",
       "  3.057480573654175,\n",
       "  3.0015339851379395,\n",
       "  2.970580816268921,\n",
       "  2.939509630203247,\n",
       "  3.55944561958313,\n",
       "  4.062826633453369,\n",
       "  3.9119772911071777,\n",
       "  4.153787136077881],\n",
       " 'sparse_categorical_accuracy': [0.1799597293138504,\n",
       "  0.21755321323871613,\n",
       "  0.20847412943840027,\n",
       "  0.22829705476760864,\n",
       "  0.23758375644683838,\n",
       "  0.24236854910850525,\n",
       "  0.24763236939907074,\n",
       "  0.2021617293357849,\n",
       "  0.16003775596618652,\n",
       "  0.15984536707401276,\n",
       "  0.15454821288585663],\n",
       " 'val_loss': [4.323082447052002,\n",
       "  2.963268756866455,\n",
       "  2.9706785678863525,\n",
       "  2.930213451385498,\n",
       "  2.8059346675872803,\n",
       "  2.7547059059143066,\n",
       "  3.3326892852783203,\n",
       "  3.3128318786621094,\n",
       "  4.795958995819092,\n",
       "  5.0748515129089355,\n",
       "  3.510409355163574],\n",
       " 'val_sparse_categorical_accuracy': [0.13866665959358215,\n",
       "  0.2365666627883911,\n",
       "  0.23313333094120026,\n",
       "  0.2489333301782608,\n",
       "  0.25966668128967285,\n",
       "  0.2720000147819519,\n",
       "  0.18310000002384186,\n",
       "  0.18596667051315308,\n",
       "  0.1004333347082138,\n",
       "  0.15870000422000885,\n",
       "  0.16923333704471588]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ccb97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "8204/8204 [==============================] - 295s 36ms/step - loss: 2.4530 - sparse_categorical_accuracy: 0.3164 - val_loss: 2.4333 - val_sparse_categorical_accuracy: 0.3209\n",
      "Epoch 2/60\n",
      "8204/8204 [==============================] - 292s 36ms/step - loss: 2.3764 - sparse_categorical_accuracy: 0.3305 - val_loss: 2.3937 - val_sparse_categorical_accuracy: 0.3289\n",
      "Epoch 3/60\n",
      "8204/8204 [==============================] - 292s 36ms/step - loss: 2.4352 - sparse_categorical_accuracy: 0.3219 - val_loss: 2.4286 - val_sparse_categorical_accuracy: 0.3209\n",
      "Epoch 4/60\n",
      "8204/8204 [==============================] - 295s 36ms/step - loss: 2.3984 - sparse_categorical_accuracy: 0.3299 - val_loss: 2.4270 - val_sparse_categorical_accuracy: 0.3192\n",
      "Epoch 5/60\n",
      "8202/8204 [============================>.] - ETA: 0s - loss: 2.4383 - sparse_categorical_accuracy: 0.3210\n",
      "Epoch 5: saving model to training6layers6thiter11inputs\\cp-0005.ckpt\n",
      "8204/8204 [==============================] - 296s 36ms/step - loss: 2.4383 - sparse_categorical_accuracy: 0.3210 - val_loss: 2.4688 - val_sparse_categorical_accuracy: 0.3102\n",
      "Epoch 6/60\n",
      "8204/8204 [==============================] - 293s 36ms/step - loss: 2.3944 - sparse_categorical_accuracy: 0.3306 - val_loss: 2.4254 - val_sparse_categorical_accuracy: 0.3249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras import layers,models,metrics,optimizers,initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "%load_ext tensorboard\n",
    "data = np.load('data/scoredPositionsFull.npz')\n",
    "actionData = np.load('data/actions.npz')\n",
    "positions = data['positions']\n",
    "positions = positions.transpose(0,2,3,1)\n",
    "# positions = np.delete(positions,np.s_[2:18],3)\n",
    "positions_mirror = positions.transpose(0,2,1,3)\n",
    "\n",
    "actions = actionData['actions']\n",
    "actions = np.delete(actions,0,1)\n",
    "actions = np.delete(actions,0,1)\n",
    "\n",
    "actions = np.delete(actions,14,1)\n",
    "actions = np.delete(actions,13,1)\n",
    "actions = np.delete(actions,0,2)\n",
    "actions = np.delete(actions,0,2)\n",
    "\n",
    "actions = np.delete(actions,14,2)\n",
    "actions = np.delete(actions,13,2)\n",
    "actions_mirror = actions.transpose(0,2,1)\n",
    "actions = np.reshape(actions,(539998,169))\n",
    "actions_mirror = np.reshape(actions_mirror, (539998,169))\n",
    "actions = np.where(actions == 1)\n",
    "actions_mirror = np.where(actions_mirror == 1)\n",
    "actions = actions[1]\n",
    "actions_mirror = actions_mirror[1]\n",
    "\n",
    "positions_test = positions[-30000:] \n",
    "actions_test = actions[-30000:]\n",
    "positions_train =np.concatenate((positions[:-30000], positions_mirror), axis= 0) \n",
    "actions_train =np.concatenate((actions[:-30000], actions_mirror), axis= 0) \n",
    "inputs = [(1,1),(2,18),(6,18),(2,6)] \n",
    "for k in range (0,1):\n",
    "    \n",
    "    positions = data['positions']\n",
    "    positions = positions.transpose(0,2,3,1)\n",
    "    if k > 0: \n",
    "        positions = np.delete(positions,np.s_[inputs[k][0]:inputs[k][1]],3)\n",
    "    positions_mirror = positions.transpose(0,2,1,3)\n",
    "    positions_test = positions[-30000:] \n",
    "    positions_train =np.concatenate((positions[:-30000], positions_mirror), axis= 0) \n",
    "    for i in range(6,7):\n",
    "\n",
    "        model = models.Sequential()\n",
    "    #     init_stddev = math.sqrt(2.0 / (18 * 5 * 5))\n",
    "        if k > 0:\n",
    "            model.add(layers.Conv2D(128,(5,5),strides = 1, activation =\"relu\",padding = \"valid\" ,input_shape=(17,17,18 - (inputs[k][1] - inputs[k][0]))))\n",
    "        else:\n",
    "            model.add(layers.Conv2D(128,(5,5),strides = 1, activation =\"relu\",padding = \"valid\" ,input_shape=(17,17,18)))\n",
    "       \n",
    "        for j in range (0,i):\n",
    "    #         init_stddev = math.sqrt(2.0 / (128 * 3 * 3))\n",
    "            model.add(layers.Conv2D(128,(3,3),strides =1,padding = \"same\",activation = \"relu\",use_bias = 1))\n",
    "\n",
    "        model.add(layers.Conv2D(1,(1,1),strides = 1))\n",
    "        model.add(layers.Flatten())\n",
    "        model.load_weights(\"DataModels/18 Inputs/DoubleDataWeights/training66layers3rdIter/cp-0027.ckpt\")\n",
    "            \n",
    "        checkpoint_path = \"training\" + str(i) + \"layers6thiter\" + str(inputs[k][0]) + str(inputs[k][1]) +  \"inputs/cp-{epoch:04d}.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,verbose = 1, save_weights_only = True, save_freq = 8204 * 5)\n",
    "        opt = optimizers.Adam(0.00001)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "        model.compile(optimizer = opt, loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics = [metrics.SparseCategoricalAccuracy()])\n",
    "        output = model.fit(positions_train,actions_train,batch_size = 128, epochs = 60,validation_data= (positions_test,actions_test),callbacks= [cp_callback,callback])\n",
    "        np.save(\"history/history6thiter\" + str(k), output.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf659ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aae7187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1365: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.NameBasedSaverStatus at 0x10eb7d0a290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"Hex data\\MoHex-CNN model\\slmodel.ckpt-135000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7ff75c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an `input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\sequential.py:344\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must provide an `input_shape` argument.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    345\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_graph_network_for_inferred_shape(input_shape)\n\u001b[0;32m    346\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide an `input_shape` argument."
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c9159e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load('data/scoredPositionsMohex21.npz')\n",
    "data2 = np.load('data/scoredPositionsMohex22.npz')\n",
    "data3 = np.load('data/scoredPositionsMohex23.npz')\n",
    "data4 = np.load('data/scoredPositionsMohex24.npz')\n",
    "data5 = np.load('data/scoredPositionsMohex25.npz')\n",
    "data6 = np.load('data/scoredPositionsMohex26.npz')\n",
    "data7 = np.load('data/scoredPositionsMohex27.npz')\n",
    "data8 = np.load('data/scoredPositionsMohex28.npz')\n",
    "\n",
    "positions = np.concatenate((data1['positions'],data2['positions'],data3['positions'],data4['positions'],data5['positions'],data6['positions'],data7['positions'],data8['positions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bd70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez( \"data/mohexPositions.npz\", positions = positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc33ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load('data/positions0.npz')\n",
    "data2 = np.load('data/positions1000.npz')\n",
    "data3= np.load('data/positions2000.npz')\n",
    "data4 = np.load('data/positions3000.npz')\n",
    "data5 = np.load('data/positions4000.npz')\n",
    "data6 = np.load('data/positions5000.npz')\n",
    "data7 = np.load('data/positions6000.npz')\n",
    "data8 = np.load('data/positions7000.npz')\n",
    "data9 = np.load('data/positions8000.npz')\n",
    "data10 = np.load('data/positions9000.npz')\n",
    "data11 = np.load('data/positions10000.npz')\n",
    "data12 = np.load('data/positions11000.npz')\n",
    "data13 = np.load('data/positions12000.npz')\n",
    "data14 = np.load('data/positions13000.npz')\n",
    "data15 = np.load('data/positions14000.npz')\n",
    "data16 = np.load('data/positions15000.npz')\n",
    "data17 = np.load('data/positions16000.npz')\n",
    "data18 = np.load('data/positions17000.npz')\n",
    "data19 = np.load('data/positions18000.npz')\n",
    "data20 = np.load('data/positions19000.npz')\n",
    "data21 = np.load('data/positions20000.npz')\n",
    "data22 = np.load('data/positions21000.npz')\n",
    "data23 = np.load('data/positions22000.npz')\n",
    "data24 = np.load('data/positionsfinal.npz')\n",
    "\n",
    "\n",
    "actions = np.concatenate((data1['positions'],data2['positions'],data3['positions'],data4['positions'],data5['positions'],data6['positions'],data7['positions'],data8['positions'],data9['positions'],data10['positions'],data11['positions'],data12['positions'],data13['positions'],data14['positions'],data15['positions'],data16['positions'],data17['positions'],data18['positions'],data19['positions'],data20['positions'],data21['positions'],data22['positions'],data23['positions'],data24['positions']))\n",
    "np.savez(\"data/mohexPositions.npz\",positions = actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3d35299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1760832, 17, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actionData = np.load('data/mohexActions.npz')\n",
    "actions = actionData['actions']\n",
    "np.shape(actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
